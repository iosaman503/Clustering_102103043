# -*- coding: utf-8 -*-
"""Clustering_102103043.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bNIkWPFv2peLZ37amNcVYFBC2MHn52nE
"""

!pip install pycaret
from pycaret.datasets import get_data
from pycaret.clustering import *
import pandas as pd
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.decomposition import PCA

columns=['sepal_length','sepal_width','petal_length','petal_width','species']
data = pd.read_csv('/content/iris.data',names=columns)

data.head()

data = data.drop(columns=['species'])

clustering_setup = setup(data)

num_clusters = [3, 4, 5]

clustering_algorithms = ['agglomerative', 'gmm', 'birch']

results_dict = {}

from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.decomposition import PCA
from sklearn.mixture import GaussianMixture
from sklearn.cluster import AgglomerativeClustering, Birch
import pandas as pd



preprocessing_techniques = {
    'None': None,
    'normalize': StandardScaler(),
    'pca': PCA(),
    'transform': None,
    'scale': MinMaxScaler()
}


clustering_algorithms = {
    'agglomerative': AgglomerativeClustering(),
    'gmm': GaussianMixture(),
    'birch': Birch()
}

num_clusters = [3, 4, 5]

results_dict = {}


for algorithm, model in clustering_algorithms.items():
    algorithm_results = pd.DataFrame(index=['Silhouette', 'Calinski-Harabasz', 'Davies-Bouldin'])
    for technique, preprocess_method in preprocessing_techniques.items():
        for n_clusters in num_clusters:
            if preprocess_method is not None:
                preprocessed_data = preprocess_method.fit_transform(data)
            else:
                preprocessed_data = data


            if algorithm == 'agglomerative':
                model = AgglomerativeClustering(n_clusters=n_clusters)
            elif algorithm == 'gmm':
                model = GaussianMixture(n_components=n_clusters)
            elif algorithm == 'birch':
                model = Birch(n_clusters=n_clusters)

            labels = model.fit_predict(preprocessed_data)


            if len(set(labels)) <= 1:
                continue


            silhouette = silhouette_score(preprocessed_data, labels)
            calinski_harabasz = calinski_harabasz_score(preprocessed_data, labels)
            davies_bouldin = davies_bouldin_score(preprocessed_data, labels)

            col_name = f'{technique}_c={n_clusters}'
            algorithm_results[col_name] = [silhouette, calinski_harabasz, davies_bouldin]


    results_dict[algorithm] = algorithm_results

results_dict

for algorithm, results in results_dict.items():
    results.to_csv(f'{algorithm}_results.csv')

import matplotlib.pyplot as plt

evaluation_metrics = ['Silhouette', 'Calinski-Harabasz', 'Davies-Bouldin']

for algorithm, results in results_dict.items():
    plt.figure(figsize=(10, 6))
    plt.title(f'{algorithm} Evaluation Metrics')
    for metric in evaluation_metrics:
        plt.bar(results.columns, results.loc[metric], label=metric)
    plt.xlabel('Number of Clusters')
    plt.ylabel('Score')
    plt.xticks(rotation=45)
    plt.legend()
    plt.tight_layout()
    plt.show()

