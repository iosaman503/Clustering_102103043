# Clustering_102103043_Assignment

## Task: Comparitive performance study of different clustering algorithms using different pre-processing techniques with different numbers of clusters on different evaluation parameters

# Introduction :

This project aims to explore and evaluate various clustering algorithms using different preprocessing techniques and numbers of clusters. Clustering is a fundamental unsupervised learning technique used to discover patterns and group similar data points together. Understanding the performance of clustering algorithms under different scenarios is crucial for selecting the most appropriate algorithm for a given dataset.

# Description :

In this project, we explore three popular clustering algorithms: Agglomerative Clustering, Gaussian Mixture Model (GMM), and Birch. We evaluate these algorithms using five preprocessing techniques: None, normalization, PCA (Principal Component Analysis), transformation, and scaling. Additionally, we assess the algorithms' performance with three different numbers of clusters: 3, 4, and 5.

For each combination of algorithm, preprocessing technique, and number of clusters, we calculate three evaluation metrics: Silhouette Score, Calinski-Harabasz Score, and Davies-Bouldin Score. These metrics provide insights into the clustering quality, compactness, and separation.

The project utilizes Python libraries such as scikit-learn and pandas for data preprocessing, clustering, and evaluation. We visualize the evaluation results using matplotlib to facilitate interpretation and comparison across different algorithms and preprocessing techniques.

# Results :

Following Results were obtained that is represented in a tabular format :

![image](https://github.com/iosaman503/Clustering_102103043/assets/90442567/a248480f-16e1-40a3-a37b-f36e0dca3470)

# Summary :

In summary, this project provides a comprehensive evaluation of clustering algorithms under various settings. By examining the performance metrics across different algorithms, preprocessing techniques, and numbers of clusters, we can gain insights into the strengths and limitations of each approach. 


